import cv2
import requests
import base64
import threading
import time
import os
import glob
from collections import deque
import matplotlib
matplotlib.use('Agg')  # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œë¡œ ë³€ê²½ (GUI ì—†ì´ íŒŒì¼ë¡œë§Œ ì €ì¥)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np
from datetime import datetime
import psutil
import gc
import signal
import sys
import json
import traceback
from concurrent.futures import ThreadPoolExecutor

# --- [ì„¤ì •] ---
API_URL = "http://127.0.0.1:8888/v1/chat/completions"
VIDEO_DIR = os.path.expanduser("~/data/video") 
LABELS = ["ABNORMAL", "NORMAL"]

# ì¥ê¸° ì‹¤í–‰ ìµœì í™” ì„¤ì •
HEADLESS_MODE = False  # Trueë¡œ ì„¤ì •í•˜ë©´ GUI ì—†ì´ ì‹¤í–‰ (ì„œë²„ í™˜ê²½ìš©)
MAX_CONCURRENT_INFERENCES = 2  # ë™ì‹œ ì¸í¼ëŸ°ìŠ¤ ì œí•œ
RESULTS_BACKUP_INTERVAL = 100  # 100ê°œë§ˆë‹¤ results ë°±ì—…
RESULTS_KEEP_IN_MEMORY = 50  # ë©”ëª¨ë¦¬ì— ìµœê·¼ 50ê°œë§Œ ìœ ì§€

# ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
LOG_DIR = os.path.expanduser("~/data/inference_logs")
os.makedirs(LOG_DIR, exist_ok=True)

# ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ (ì¤‘ë‹¨ëœ ìœ„ì¹˜ ì €ì¥)
CHECKPOINT_DIR = os.path.join(LOG_DIR, "checkpoints")
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# ë°±ì—… ë””ë ‰í† ë¦¬
BACKUP_DIR = os.path.join(LOG_DIR, "backups")
os.makedirs(BACKUP_DIR, exist_ok=True)

# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (ì‹¤í–‰ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')

# í†µí•© ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
CONSOLIDATED_LOG = os.path.join(LOG_DIR, f"all_results_{RUN_TIMESTAMP}.txt")
CHECKPOINT_FILE = os.path.join(CHECKPOINT_DIR, f"progress_{RUN_TIMESTAMP}.json")
ERROR_LOG = os.path.join(LOG_DIR, f"errors_{RUN_TIMESTAMP}.txt")

# 2ì§„ ë¶„ë¥˜ìš© ìƒ‰ìƒ ì •ì˜ (BGR)
CLASS_COLORS = {
    "NORMAL": (0, 255, 0),       # Green
    "ABNORMAL": (0, 0, 255),     # Red
    "UNCERTAIN": (0, 255, 255),  # Yellow
    "INITIALIZING": (100, 100, 100), # Gray
    "API ERROR": (0, 165, 255),  # Orange
    "TIMEOUT": (128, 128, 128)   # Dark Gray
}

WINDOW_SIZE = 8
STRIDE = 6

# API ì¬ì‹œë„ ì„¤ì •
MAX_API_RETRIES = 3
API_RETRY_DELAY = 2  # seconds
API_TIMEOUT = 15  # seconds (ì¥ê¸° ì‹¤í–‰ìš©ìœ¼ë¡œ ì¦ê°€)

# ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •
MEMORY_CHECK_INTERVAL = 10  # 10ê°œ ë¹„ë””ì˜¤ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì²´í¬
MEMORY_THRESHOLD_PERCENT = 85  # 85% ì´ìƒ ì‚¬ìš© ì‹œ ê²½ê³ 
GC_COLLECT_INTERVAL = 5  # 5ê°œ ë¹„ë””ì˜¤ë§ˆë‹¤ ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
DISK_SPACE_CHECK_INTERVAL = 50  # 50ê°œë§ˆë‹¤ ë””ìŠ¤í¬ ê³µê°„ ì²´í¬
DISK_SPACE_THRESHOLD = 90  # 90% ì´ìƒ ì‚¬ìš© ì‹œ ê²½ê³ 

# GUI ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
GUI_REFRESH_INTERVAL = 50  # 50ê°œë§ˆë‹¤ GUI ìœˆë„ìš° ì¬ìƒì„±

# --- [ì „ì—­ ë³€ìˆ˜] ---
latest_label = "INITIALIZING"
latest_color = CLASS_COLORS["INITIALIZING"]
is_processing = False
last_latency = 0.0
frame_buffer = deque(maxlen=WINDOW_SIZE)
new_frame_count = 0 
last_capture_time = 0

current_video_stats = [] 
timeline_data = []       
inference_triggers = []  
all_results = []

# ì¸í¼ëŸ°ìŠ¤ ë¡œê·¸ ì €ì¥ìš©
current_video_inferences = []

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ í”Œë˜ê·¸
shutdown_flag = False

# í†µê³„ ì •ë³´
stats = {
    'total_processed': 0,
    'total_errors': 0,
    'api_timeouts': 0,
    'api_errors': 0,
    'videos_skipped': 0,
    'start_time': time.time(),
    'last_backup_time': time.time(),
    'total_backups': 0
}

# ìŠ¤ë ˆë“œ í’€ executor
inference_executor = ThreadPoolExecutor(max_workers=MAX_CONCURRENT_INFERENCES)

def signal_handler(sig, frame):
    """Ctrl+C ë“± ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬"""
    global shutdown_flag
    print("\n\nâš ï¸  Shutdown signal received. Saving progress...")
    shutdown_flag = True
    save_checkpoint()
    backup_results(force=True)
    inference_executor.shutdown(wait=True, cancel_futures=True)
    print("âœ… Progress saved. Exiting gracefully.")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def log_error(error_msg, video_filename=""):
    """ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    try:
        with open(ERROR_LOG, 'a', encoding='utf-8') as f:
            f.write(f"[{timestamp}] {video_filename}: {error_msg}\n")
        print(f"âŒ Error logged: {error_msg}")
    except Exception as e:
        print(f"âš ï¸ Failed to write error log: {e}")

def check_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ë° ê²½ê³ """
    try:
        memory = psutil.virtual_memory()
        percent = memory.percent
        
        if percent > MEMORY_THRESHOLD_PERCENT:
            print(f"âš ï¸  High memory usage: {percent:.1f}% - Running garbage collection...")
            gc.collect()
            memory_after = psutil.virtual_memory()
            print(f"   Memory after GC: {memory_after.percent:.1f}%")
        
        return percent
    except Exception as e:
        print(f"âš ï¸ Memory check failed: {e}")
        return 0

def check_disk_space():
    """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
    try:
        disk = psutil.disk_usage(LOG_DIR)
        percent = disk.percent
        
        if percent > DISK_SPACE_THRESHOLD:
            print(f"âš ï¸  WARNING: Disk space critical - {percent:.1f}% used!")
            print(f"   Free space: {disk.free / (1024**3):.2f} GB")
            return False
        
        return True
    except Exception as e:
        print(f"âš ï¸ Disk space check failed: {e}")
        return True

def backup_results(force=False):
    """ë©”ëª¨ë¦¬ì—ì„œ resultsë¥¼ ë””ìŠ¤í¬ë¡œ ë°±ì—…í•˜ê³  ì •ë¦¬"""
    global all_results
    
    if not all_results:
        return
    
    try:
        backup_file = os.path.join(BACKUP_DIR, f"results_backup_{stats['total_processed']}_{RUN_TIMESTAMP}.json")
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2)
        
        stats['total_backups'] += 1
        stats['last_backup_time'] = time.time()
        print(f"ğŸ’¾ Backed up {len(all_results)} results to: {backup_file}")
        
        if not force:
            # ìµœê·¼ ê²°ê³¼ë§Œ ë©”ëª¨ë¦¬ì— ìœ ì§€
            all_results = all_results[-RESULTS_KEEP_IN_MEMORY:]
            print(f"   Kept {len(all_results)} most recent results in memory")
        
        gc.collect()
        
    except Exception as e:
        log_error(f"Failed to backup results: {e}")

def load_all_backups():
    """ëª¨ë“  ë°±ì—… íŒŒì¼ì—ì„œ results ë¡œë“œ"""
    all_backup_results = []
    
    try:
        backup_files = sorted(glob.glob(os.path.join(BACKUP_DIR, f"results_backup_*_{RUN_TIMESTAMP}.json")))
        
        for backup_file in backup_files:
            with open(backup_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
                all_backup_results.extend(results)
        
        print(f"ğŸ“‚ Loaded {len(all_backup_results)} results from {len(backup_files)} backup files")
        return all_backup_results
        
    except Exception as e:
        print(f"âš ï¸ Failed to load backups: {e}")
        return []

def save_checkpoint():
    """í˜„ì¬ ì§„í–‰ ìƒí™© ì €ì¥"""
    checkpoint_data = {
        'timestamp': datetime.now().isoformat(),
        'processed_count': stats['total_processed'],
        'completed_videos': [r['filename'] for r in all_results],
        'stats': stats,
        'run_id': RUN_TIMESTAMP
    }
    
    try:
        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, indent=2)
        print(f"ğŸ’¾ Checkpoint saved: {stats['total_processed']} videos processed")
    except Exception as e:
        print(f"âš ï¸  Failed to save checkpoint: {e}")
        log_error(f"Checkpoint save failed: {e}")

def load_checkpoint():
    """ì´ì „ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    if not os.path.exists(CHECKPOINT_FILE):
        return None
    
    try:
        with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
            checkpoint = json.load(f)
        print(f"ğŸ“‚ Found checkpoint: {len(checkpoint['completed_videos'])} videos already processed")
        return checkpoint
    except Exception as e:
        print(f"âš ï¸  Failed to load checkpoint: {e}")
        return None

def frame_to_base64(frame):
    """í”„ë ˆì„ì„ base64ë¡œ ë³€í™˜ (ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€)"""
    try:
        resized = cv2.resize(frame, (320, 240)) 
        _, buffer = cv2.imencode('.jpg', resized, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
        return base64.b64encode(buffer).decode('utf-8')
    except Exception as e:
        log_error(f"Frame encoding error: {e}")
        return None

def draw_timeline(frame, current_frame, total_frames, history, triggers, fps):
    """íƒ€ì„ë¼ì¸ ê·¸ë¦¬ê¸° (ì—ëŸ¬ ë°©ì§€)"""
    try:
        h, w = frame.shape[:2]
        bar_height = 30
        y_start = h - bar_height
        
        if total_frames <= 0 or fps <= 0: 
            return

        progress_ratio = min(1.0, max(0.0, current_frame / total_frames))
        
        cv2.rectangle(frame, (0, y_start), (w, h), (40, 40, 40), -1)

        cur_x = int(progress_ratio * w)

        start_x = 0
        for item in history:
            end_frame = item['frame']
            ratio = min(1.0, end_frame / total_frames)
            end_x = int(ratio * w)
            draw_end_x = min(end_x, cur_x)
            color = CLASS_COLORS.get(item['label'], (100, 100, 100))
            if draw_end_x > start_x:
                cv2.rectangle(frame, (start_x, y_start), (draw_end_x, h), color, -1)
            start_x = end_x
            if start_x >= cur_x: 
                break
                
        if start_x < cur_x:
            waiting_color = CLASS_COLORS["INITIALIZING"]
            cv2.rectangle(frame, (start_x, y_start), (cur_x, h), waiting_color, -1)

        for trig_frame in triggers:
            trig_ratio = min(1.0, trig_frame / total_frames)
            trig_x = int(trig_ratio * w)
            cv2.line(frame, (trig_x, y_start), (trig_x, h), (255, 255, 255), 1)

        total_seconds = total_frames / fps
        step_seconds = max(1, int(total_seconds / 6)) 
        font_color = (200, 200, 200)
        
        for t_sec in range(0, int(total_seconds) + 1, step_seconds):
            ratio = t_sec / total_seconds if total_seconds > 0 else 0
            x_pos = int(ratio * w)
            cv2.line(frame, (x_pos, y_start), (x_pos, y_start - 5), font_color, 1)
            time_str = f"{t_sec}s"
            cv2.putText(frame, time_str, (x_pos + 2, y_start - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.4, font_color, 1)

        cv2.rectangle(frame, (cur_x, y_start), (min(w, cur_x + 2), h), (255, 255, 255), -1)
        
        current_seconds = current_frame / fps
        cur_time_str = f"{current_seconds:.1f}s"
        (tw, th), _ = cv2.getTextSize(cur_time_str, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        
        text_x = cur_x - tw // 2
        text_x = max(0, min(w - tw, text_x))
        text_y = y_start - 25
        
        cv2.rectangle(frame, (text_x - 2, text_y - th - 2), (text_x + tw + 2, text_y + 2), (0, 0, 0), -1)
        cv2.putText(frame, cur_time_str, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
    except Exception as e:
        # íƒ€ì„ë¼ì¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        pass

# --- ì¸í¼ëŸ°ìŠ¤ ì›Œì»¤ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€) ---
def request_inference(b64_list, capture_frame_idx, fps, retry_count=0):
    """API ìš”ì²­ with ì¬ì‹œë„ ë¡œì§"""
    global latest_label, latest_color, is_processing, last_latency, current_video_stats, timeline_data, current_video_inferences, stats
    start_t = time.time()
    
    system_instruction = (
    "Role: You are a strict CCTV Safety AI. Your goal is to detect PROVEN anomalies only.\n"
    "Task: Classify the video segment as 'Normal' or 'Abnormal'.\n\n"
    "[Definitions]\n"
    "1. Abnormal (CRITICAL & CLEAR Events Only):\n"
    "   - Violence: Fighting, Punching, Kicking, Shooting, Assault.\n"
    "   - Group Violence: Multiple people tangled, wrestling, or aggressive group brawl.\n"
    "   - Sudden Attack: Fast swinging arm (punching), sudden lunge at a person.\n"
    "   - Crime: Robbery, Burglary, Shoplifting, Vandalism, Arson.\n"
    "   - Disaster: Explosion, Car Accident, Fire.\n"
    "   * NOTE: The event must be visually clear and happening right now.\n\n"
    "2. Normal (Safe or Unclear Situations):\n"
    "   - Routine: Walking, Running (jogging/hurrying), Standing, Sitting, Crowds.\n"
    "   - Environment: Dark scenes, Blurry footage, Moving shadows.\n\n"
    "Output Requirement: Output ONLY the single word 'Normal' or 'Abnormal' without any punctuation."
    )

    content_list = [{"type": "text", "text": system_instruction}]
    for b64_img in b64_list:
        if b64_img:  # None ì²´í¬
            content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}})

    payload = {
        "model": "Qwen3-VL-2B-Instruct", 
        "messages": [{"role": "user", "content": content_list}],
        "max_tokens": 5, 
        "temperature": 0.0 
    }

    try:
        response = requests.post(API_URL, json=payload, timeout=API_TIMEOUT)
        latency = time.time() - start_t
        
        if response.status_code == 200:
            raw_content = response.json()['choices'][0]['message']['content'].strip().upper()
            
            if "ABNORMAL" in raw_content or "DANGER" in raw_content or "FIGHT" in raw_content:
                pred_label = "ABNORMAL"
            elif "NORMAL" in raw_content:
                pred_label = "NORMAL"
            else:
                pred_label = "UNCERTAIN" 

            latest_label = pred_label
            latest_color = CLASS_COLORS.get(pred_label, CLASS_COLORS["UNCERTAIN"])
            
            current_video_stats.append(pred_label)
            timeline_data.append({'frame': capture_frame_idx, 'label': pred_label})

            timestamp_seconds = capture_frame_idx / fps if fps > 0 else 0
            current_video_inferences.append({
                'frame': capture_frame_idx,
                'timestamp': timestamp_seconds,
                'label': pred_label,
                'latency': latency,
                'raw_response': raw_content
            })

            last_latency = latency
            print(f"  -> [AI Segment] Frame {capture_frame_idx}: {latest_label} ({latency:.2f}s)")
            
        else:
            # HTTP ì—ëŸ¬ ì‹œ ì¬ì‹œë„
            if retry_count < MAX_API_RETRIES:
                print(f"âš ï¸  API Error {response.status_code}, retrying ({retry_count + 1}/{MAX_API_RETRIES})...")
                time.sleep(API_RETRY_DELAY)
                return request_inference(b64_list, capture_frame_idx, fps, retry_count + 1)
            
            print(f"âŒ API Error after {MAX_API_RETRIES} retries: {response.status_code}")
            stats['api_errors'] += 1
            latest_label = "API ERROR"
            latest_color = CLASS_COLORS["API ERROR"]
            
            timestamp_seconds = capture_frame_idx / fps if fps > 0 else 0
            current_video_inferences.append({
                'frame': capture_frame_idx,
                'timestamp': timestamp_seconds,
                'label': "API ERROR",
                'latency': time.time() - start_t,
                'raw_response': f"HTTP {response.status_code}"
            })

    except requests.exceptions.Timeout:
        # íƒ€ì„ì•„ì›ƒ ì‹œ ì¬ì‹œë„
        if retry_count < MAX_API_RETRIES:
            print(f"âš ï¸  API Timeout, retrying ({retry_count + 1}/{MAX_API_RETRIES})...")
            time.sleep(API_RETRY_DELAY)
            return request_inference(b64_list, capture_frame_idx, fps, retry_count + 1)
        
        print(f"âŒ API Timeout after {MAX_API_RETRIES} retries")
        stats['api_timeouts'] += 1
        latest_label = "TIMEOUT"
        latest_color = CLASS_COLORS["TIMEOUT"]
        
        timestamp_seconds = capture_frame_idx / fps if fps > 0 else 0
        current_video_inferences.append({
            'frame': capture_frame_idx,
            'timestamp': timestamp_seconds,
            'label': "TIMEOUT",
            'latency': time.time() - start_t,
            'raw_response': "Request timeout"
        })
    
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ ì‹œ ì¬ì‹œë„
        if retry_count < MAX_API_RETRIES:
            print(f"âš ï¸  Request Error: {e}, retrying ({retry_count + 1}/{MAX_API_RETRIES})...")
            time.sleep(API_RETRY_DELAY)
            return request_inference(b64_list, capture_frame_idx, fps, retry_count + 1)
        
        print(f"âŒ Request Error after {MAX_API_RETRIES} retries: {e}")
        stats['total_errors'] += 1
        log_error(f"Inference request failed: {e}")
        latest_label = "TIMEOUT"
        latest_color = CLASS_COLORS["TIMEOUT"]
        
        timestamp_seconds = capture_frame_idx / fps if fps > 0 else 0
        current_video_inferences.append({
            'frame': capture_frame_idx,
            'timestamp': timestamp_seconds,
            'label': "TIMEOUT",
            'latency': time.time() - start_t,
            'raw_response': str(e)
        })
    
    finally:
        is_processing = False

def save_inference_log(video_filename, inferences, ground_truth, final_verdict, total_frames, fps):
    """ì˜ìƒë³„ ì¸í¼ëŸ°ìŠ¤ ê²°ê³¼ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥"""
    if not inferences:
        print(f"  [Warning] No inferences to save for {video_filename}")
        return
    
    base_name = os.path.splitext(video_filename)[0]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"{base_name}_{timestamp}.txt"
    log_path = os.path.join(LOG_DIR, log_filename)
    
    try:
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write(f"VIDEO INFERENCE LOG\n")
            f.write("="*80 + "\n")
            f.write(f"Video File: {video_filename}\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total Frames: {total_frames}\n")
            f.write(f"FPS: {fps:.2f}\n")
            f.write(f"Video Duration: {total_frames/fps:.2f}s\n")
            f.write(f"Ground Truth: {ground_truth}\n")
            f.write(f"Final Verdict: {final_verdict}\n")
            f.write(f"Total Inferences: {len(inferences)}\n")
            f.write("="*80 + "\n\n")
            
            f.write("INFERENCE RESULTS:\n")
            f.write("-"*80 + "\n")
            f.write(f"{'#':<4} {'Frame':<8} {'Time(s)':<10} {'Label':<12} {'Latency(s)':<12} {'Raw Response'}\n")
            f.write("-"*80 + "\n")
            
            for idx, inf in enumerate(inferences, 1):
                frame_num = inf['frame']
                timestamp = inf['timestamp']
                label = inf['label']
                latency = inf['latency']
                raw_resp = inf['raw_response'][:50]
                
                f.write(f"{idx:<4} {frame_num:<8} {timestamp:<10.2f} {label:<12} {latency:<12.3f} {raw_resp}\n")
            
            f.write("-"*80 + "\n\n")
            
            normal_count = sum(1 for inf in inferences if inf['label'] == 'NORMAL')
            abnormal_count = sum(1 for inf in inferences if inf['label'] == 'ABNORMAL')
            uncertain_count = sum(1 for inf in inferences if inf['label'] == 'UNCERTAIN')
            error_count = sum(1 for inf in inferences if inf['label'] in ['API ERROR', 'TIMEOUT'])
            
            avg_latency = sum(inf['latency'] for inf in inferences) / len(inferences)
            
            f.write("STATISTICS:\n")
            f.write("-"*80 + "\n")
            f.write(f"Normal Predictions: {normal_count} ({normal_count/len(inferences)*100:.1f}%)\n")
            f.write(f"Abnormal Predictions: {abnormal_count} ({abnormal_count/len(inferences)*100:.1f}%)\n")
            f.write(f"Uncertain Predictions: {uncertain_count} ({uncertain_count/len(inferences)*100:.1f}%)\n")
            f.write(f"Errors/Timeouts: {error_count} ({error_count/len(inferences)*100:.1f}%)\n")
            f.write(f"Average Latency: {avg_latency:.3f}s\n")
            f.write("-"*80 + "\n\n")
            
            f.write("VERDICT REASONING:\n")
            f.write("-"*80 + "\n")
            f.write(f"Final Verdict: {final_verdict}\n")
            f.write(f"Ground Truth: {ground_truth}\n")
            f.write(f"Result: {'âœ“ CORRECT' if final_verdict == ground_truth else 'âœ— INCORRECT'}\n")
            f.write("="*80 + "\n")
        
        return log_path
        
    except Exception as e:
        log_error(f"Failed to save log for {video_filename}: {e}")
        return None

def save_consolidated_results(video_filename, inferences):
    """ëª¨ë“  ì˜ìƒì˜ ìœˆë„ìš°ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•œ íŒŒì¼ì— ëˆ„ì  ì €ì¥"""
    try:
        labels = [inf['label'] for inf in inferences]
        labels_str = ' '.join(labels)
        
        with open(CONSOLIDATED_LOG, 'a', encoding='utf-8') as f:
            f.write(f"{video_filename} {labels_str}\n")
        
        return True
    except Exception as e:
        log_error(f"Failed to append to consolidated log: {e}")
        return False

def get_video_files(directory):
    """ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    if not os.path.exists(directory):
        return []
    extensions = ('*.mp4', '*.avi', '*.mkv', '*.mov', '*.webm')
    files = []
    for ext in extensions:
        files.extend(glob.glob(os.path.join(directory, "**", ext), recursive=True))
    return sorted(files)

def draw_ui(frame, filename, label, color, latency):
    """UI ê·¸ë¦¬ê¸° (ì—ëŸ¬ ë°©ì§€)"""
    try:
        h, w = frame.shape[:2]
        
        if label == "ABNORMAL":
            cv2.rectangle(frame, (0, 0), (w, h - 30), color, 10) 

        font = cv2.FONT_HERSHEY_SIMPLEX
        box_bottom = h - 45
        
        cv2.putText(frame, f"{label}", (20, box_bottom), font, 1.0, (0, 0, 0), 4, cv2.LINE_AA)
        cv2.putText(frame, f"{label}", (20, box_bottom), font, 1.0, color, 2, cv2.LINE_AA)
        
        info = f"{filename[:20]}.."
        cv2.putText(frame, info, (20, box_bottom - 35), font, 0.5, (200, 200, 200), 1, cv2.LINE_AA)

        lat_text = f"Lat: {latency:.2f}s"
        (lw, lh), _ = cv2.getTextSize(lat_text, font, 0.6, 1)
        lx = w - lw - 20
        ly = 40
        
        cv2.rectangle(frame, (lx - 5, ly - lh - 5), (lx + lw + 5, ly + 5), (0, 0, 0), -1)
        cv2.putText(frame, lat_text, (lx, ly), font, 0.6, (0, 255, 0), 1, cv2.LINE_AA)
    except Exception as e:
        pass  # UI ê·¸ë¦¬ê¸° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

def get_ground_truth(filename):
    """íŒŒì¼ëª…ì—ì„œ Ground Truth ì¶”ì¶œ"""
    fname_lower = filename.lower()
    if "normal" in fname_lower:
        return "NORMAL"
    else:
        return "ABNORMAL"

def check_final_verdict(stats):
    """ìµœì¢… íŒì • ë¡œì§"""
    n = len(stats)
    if n < 2: 
        return "ABNORMAL" if "ABNORMAL" in stats else "NORMAL"
    for i in range(n - 1):
        if stats[i] == "ABNORMAL" and stats[i+1] == "ABNORMAL":
            return "ABNORMAL"
    if n >= 10:
        for i in range(n - 9):
            window = stats[i:i+10]
            if window.count("ABNORMAL") >= 3:
                return "ABNORMAL"
    return "NORMAL"

def plot_beautiful_matrix(results):
    """Confusion Matrix í”Œë¡¯ (íŒŒì¼ë¡œ ì €ì¥)"""
    if not results: 
        return
    
    try:
        y_true = [r['true'] for r in results]
        y_pred = [r['pred'] for r in results]
        cm = confusion_matrix(y_true, y_pred, labels=LABELS)
        accuracy = np.trace(cm) / np.sum(cm) if np.sum(cm) > 0 else 0
        
        plt.figure(figsize=(8, 7))
        sns.set(font_scale=1.2)
        ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                         xticklabels=LABELS, yticklabels=LABELS,
                         annot_kws={"size": 16}, cbar=False)
        plt.title(f"Confusion Matrix (Acc: {accuracy:.1%})", fontsize=16, pad=20)
        plt.ylabel('Actual Label', fontsize=14)
        plt.xlabel('Predicted Label', fontsize=14)
        plt.tight_layout()
        
        # íŒŒì¼ë¡œ ì €ì¥
        plot_path = os.path.join(LOG_DIR, f"confusion_matrix_{RUN_TIMESTAMP}.png")
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š Confusion matrix saved: {plot_path}")
        
    except Exception as e:
        log_error(f"Failed to create confusion matrix: {e}")

def print_final_summary(results):
    """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
    if not results: 
        return
    
    print("\n" + "="*80)
    print(f"ğŸ“„ FINAL PROCESSING REPORT ({len(results)} Videos)")
    print("="*80)
    print(f"{'FILENAME':<35} | {'PREDICT':<10} | {'TRUTH':<10} | {'RESULT'}")
    print("-" * 80)
    
    correct_cnt = 0
    for res in results:
        fname = res['filename']
        if len(fname) > 33: 
            fname = fname[:30] + "..."
        pred = res['pred']
        gt = res['true']
        is_correct = (pred == gt)
        if is_correct: 
            correct_cnt += 1
            mark = "âœ… OK"
        else:
            mark = "âŒ FAIL"
        print(f"{fname:<35} | {pred:<10} | {gt:<10} | {mark}")
    
    acc = correct_cnt / len(results) * 100
    elapsed_time = time.time() - stats['start_time']
    elapsed_hours = elapsed_time / 3600
    
    print("-" * 80)
    print(f"ğŸ“Š Total Accuracy: {acc:.2f}% ({correct_cnt}/{len(results)})")
    print(f"â±ï¸  Elapsed Time: {elapsed_hours:.2f} hours ({elapsed_time/86400:.2f} days)")
    print(f"ğŸ¬ Videos Processed: {stats['total_processed']}")
    print(f"âš ï¸  API Timeouts: {stats['api_timeouts']}")
    print(f"âŒ API Errors: {stats['api_errors']}")
    print(f"â­ï¸  Videos Skipped: {stats['videos_skipped']}")
    print(f"ğŸ’¾ Total Backups: {stats['total_backups']}")
    print("="*80 + "\n")

def print_progress_stats():
    """ì§„í–‰ ìƒí™© í†µê³„ ì¶œë ¥"""
    elapsed = time.time() - stats['start_time']
    elapsed_hours = elapsed / 3600
    elapsed_days = elapsed / 86400
    memory_percent = psutil.virtual_memory().percent
    
    try:
        disk = psutil.disk_usage(LOG_DIR)
        disk_percent = disk.percent
        disk_free_gb = disk.free / (1024**3)
    except:
        disk_percent = 0
        disk_free_gb = 0
    
    print("\n" + "-"*80)
    print(f"â±ï¸  Runtime: {elapsed_hours:.2f}h ({elapsed_days:.2f} days) | Processed: {stats['total_processed']} videos")
    print(f"ğŸ“Š Memory: {memory_percent:.1f}% | Disk: {disk_percent:.1f}% ({disk_free_gb:.1f}GB free)")
    print(f"âŒ Errors: {stats['total_errors']} | Timeouts: {stats['api_timeouts']} | Backups: {stats['total_backups']}")
    print("-"*80 + "\n")

def refresh_gui_window():
    """GUI ìœˆë„ìš° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ì¬ìƒì„±"""
    if not HEADLESS_MODE:
        try:
            cv2.destroyAllWindows()
            time.sleep(0.5)
            print("ğŸ”„ GUI window refreshed")
        except Exception as e:
            print(f"âš ï¸ GUI refresh failed: {e}")

# --- [ë©”ì¸ ì‹¤í–‰] ---
if __name__ == "__main__":
    print("="*80)
    print("ğŸš€ ULTRA LONG-RUN VIDEO ANALYSIS SYSTEM (128h Optimized)")
    print("="*80)
    print(f"ğŸ“‚ Video Directory: {VIDEO_DIR}")
    print(f"ğŸ’¾ Log Directory: {LOG_DIR}")
    print(f"ğŸ”„ Checkpoint File: {CHECKPOINT_FILE}")
    print(f"âš™ï¸  API Timeout: {API_TIMEOUT}s | Max Retries: {MAX_API_RETRIES}")
    print(f"ğŸ§µ Max Concurrent Inferences: {MAX_CONCURRENT_INFERENCES}")
    print(f"ğŸ’¾ Results Backup: Every {RESULTS_BACKUP_INTERVAL} videos")
    print(f"ğŸ–¥ï¸  Headless Mode: {'ENABLED' if HEADLESS_MODE else 'DISABLED'}")
    print("="*80 + "\n")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = load_checkpoint()
    completed_videos = set(checkpoint['completed_videos']) if checkpoint else set()
    
    video_files = get_video_files(VIDEO_DIR)
    
    if not video_files:
        print(f"âŒ Error: No videos found in {VIDEO_DIR}")
        exit()

    print(f"ğŸ“‚ Found {len(video_files)} total videos.")
    
    if completed_videos:
        remaining_videos = [v for v in video_files if os.path.basename(v) not in completed_videos]
        print(f"âœ… Already completed: {len(completed_videos)} videos")
        print(f"ğŸ“‹ Remaining: {len(remaining_videos)} videos")
        video_files = remaining_videos
    
    if not video_files:
        print("âœ… All videos already processed!")
        exit()
    
    print(f"\nâ–¶ï¸  Starting processing of {len(video_files)} videos...\n")
    
    for video_idx, video_path in enumerate(video_files, 1):
        if shutdown_flag:
            print("\nâš ï¸  Shutdown requested. Stopping...")
            break
        
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"âš ï¸  Failed to open video: {video_path}")
                stats['videos_skipped'] += 1
                log_error(f"Failed to open video", os.path.basename(video_path))
                continue

            filename = os.path.basename(video_path)
            true_label = get_ground_truth(filename)
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if total_frames <= 0: 
                total_frames = 1
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            if fps <= 0: 
                fps = 30
            wait_ms = max(1, int(1000 / fps))

            # ì´ˆê¸°í™”
            frame_buffer.clear()
            current_video_stats = []
            timeline_data = [] 
            inference_triggers = []
            current_video_inferences = []
            
            latest_label = "SCANNING..."
            latest_color = CLASS_COLORS["INITIALIZING"]
            new_frame_count = 0
            last_capture_time = 0 
            current_frame_pos = 0
            last_frame_disp = None 

            print(f"\n[{video_idx}/{len(video_files)}] â–¶ Playing: {filename} (GT: {true_label})")

            # ë¹„ë””ì˜¤ ì²˜ë¦¬ ë£¨í”„
            while True:
                if shutdown_flag:
                    break
                
                ret, frame = cap.read()
                if not ret: 
                    break 

                current_frame_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))

                if current_frame_pos > total_frames:
                    total_frames = current_frame_pos

                if frame.shape[1] < 640:
                    frame = cv2.resize(frame, (640, int(640 * frame.shape[0] / frame.shape[1])))
                
                last_frame_disp = frame.copy()
                curr_t = time.time()

                # ì£¼ê¸°ì  ìƒ˜í”Œë§
                if curr_t - last_capture_time > 0.25:
                    last_capture_time = curr_t
                    img_b64 = frame_to_base64(frame)
                    if img_b64:  # Noneì´ ì•„ë‹ ë•Œë§Œ ì¶”ê°€
                        frame_buffer.append(img_b64)
                        new_frame_count += 1

                    if len(frame_buffer) == WINDOW_SIZE and new_frame_count >= STRIDE:
                        if not is_processing:
                            is_processing = True
                            new_frame_count = 0
                            
                            inference_triggers.append(current_frame_pos)
                            
                            # ThreadPoolExecutor ì‚¬ìš©
                            inference_executor.submit(request_inference, list(frame_buffer), current_frame_pos, fps)

                if not HEADLESS_MODE:
                    draw_ui(frame, filename, latest_label, latest_color, last_latency)
                    draw_timeline(frame, current_frame_pos, total_frames, timeline_data, inference_triggers, fps)
                    
                    cv2.imshow('Safe Long-Run Video Analysis', frame)

                    key = cv2.waitKey(wait_ms) & 0xFF
                    if key == ord('q'): 
                        shutdown_flag = True
                        break
                    elif key == ord('n'):
                        break 
                else:
                    # Headless mode: ì£¼ê¸°ì ìœ¼ë¡œ ì§„í–‰ ìƒí™©ë§Œ ì¶œë ¥
                    if current_frame_pos % 300 == 0:  # 10ì´ˆë§ˆë‹¤
                        progress = (current_frame_pos / total_frames) * 100
                        print(f"  Progress: {progress:.1f}% ({current_frame_pos}/{total_frames} frames)")

            cap.release()
            
            # ë§ˆì§€ë§‰ ì¸í¼ëŸ°ìŠ¤ ì²˜ë¦¬
            if not shutdown_flag:
                pending_inference = is_processing
                needs_flush = (len(frame_buffer) > 0)
                
                if pending_inference or needs_flush:
                    print(f"  [System] Finalizing analysis...", end="", flush=True)
                    
                    if not is_processing and needs_flush:
                        is_processing = True
                        inference_triggers.append(current_frame_pos)
                        inference_executor.submit(request_inference, list(frame_buffer), current_frame_pos, fps)
                    
                    # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                    wait_start = time.time()
                    while is_processing and (time.time() - wait_start < 30):
                        if not HEADLESS_MODE and last_frame_disp is not None:
                            freeze_frame = last_frame_disp.copy()
                            draw_ui(freeze_frame, filename, "FINALIZING...", CLASS_COLORS["INITIALIZING"], last_latency)
                            draw_timeline(freeze_frame, total_frames, total_frames, timeline_data, inference_triggers, fps)
                            cv2.imshow('Safe Long-Run Video Analysis', freeze_frame)
                            cv2.waitKey(50)
                        else:
                            time.sleep(0.5)
                    
                    print(" Done.")

                # ê²°ê³¼ ì €ì¥
                final_verdict = check_final_verdict(current_video_stats)
                
                save_inference_log(filename, current_video_inferences, true_label, final_verdict, total_frames, fps)
                
                if current_video_inferences:
                    save_consolidated_results(filename, current_video_inferences)
                
                all_results.append({
                    'filename': filename,
                    'true': true_label,
                    'pred': final_verdict
                })
                
                stats['total_processed'] += 1
                print(f"âœ… Verdict: [{final_verdict}] (GT: {true_label})")
            
            # ì£¼ê¸°ì ì¸ ë©”ëª¨ë¦¬ ì²´í¬ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            if video_idx % MEMORY_CHECK_INTERVAL == 0:
                check_memory_usage()
            
            if video_idx % GC_COLLECT_INTERVAL == 0:
                gc.collect()
            
            # ë””ìŠ¤í¬ ê³µê°„ ì²´í¬
            if video_idx % DISK_SPACE_CHECK_INTERVAL == 0:
                if not check_disk_space():
                    print("âš ï¸  WARNING: Consider cleaning up old logs or expanding disk space!")
            
            # Results ë°±ì—…
            if video_idx % RESULTS_BACKUP_INTERVAL == 0:
                backup_results()
            
            # ì£¼ê¸°ì ì¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (10ê°œë§ˆë‹¤)
            if video_idx % 10 == 0:
                save_checkpoint()
                print_progress_stats()
            
            # GUI ìœˆë„ìš° ë¦¬í”„ë ˆì‹œ
            if not HEADLESS_MODE and video_idx % GUI_REFRESH_INTERVAL == 0:
                refresh_gui_window()
        
        except Exception as e:
            print(f"\nâŒ Critical error processing {os.path.basename(video_path)}: {e}")
            log_error(f"Critical error: {traceback.format_exc()}", os.path.basename(video_path))
            stats['total_errors'] += 1
            stats['videos_skipped'] += 1
            
            # ì—ëŸ¬ ë°œìƒí•´ë„ ë‹¤ìŒ ë¹„ë””ì˜¤ë¡œ ê³„ì† ì§„í–‰
            try:
                cap.release()
            except:
                pass
            continue

    # ì •ë¦¬
    if not HEADLESS_MODE:
        cv2.destroyAllWindows()
    
    # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
    inference_executor.shutdown(wait=True)
    
    # ìµœì¢… ë°±ì—…
    backup_results(force=True)
    
    # ëª¨ë“  ë°±ì—… ë¡œë“œí•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    all_backup_results = load_all_backups()
    if all_backup_results:
        all_results = all_backup_results
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
    save_checkpoint()
    print_final_summary(all_results)
    plot_beautiful_matrix(all_results)
    
    print("\n" + "="*80)
    print(f"ğŸ“ All window-level results saved to:")
    print(f"   {CONSOLIDATED_LOG}")
    print(f"ğŸ’¾ Checkpoint saved to:")
    print(f"   {CHECKPOINT_FILE}")
    print(f"ğŸ’¾ Results backups in:")
    print(f"   {BACKUP_DIR}")
    print(f"âŒ Error log saved to:")
    print(f"   {ERROR_LOG}")
    print("="*80)
    
    elapsed = time.time() - stats['start_time']
    print(f"\nâœ… Long-run processing completed successfully!")
    print(f"â±ï¸  Total Runtime: {elapsed/3600:.2f} hours ({elapsed/86400:.2f} days)")